# คู่มือสำหรับนักพัฒนา MANTA

## บทนำ

คู่มือนี้จัดทำขึ้นสำหรับนักพัฒนาที่ต้องการมีส่วนร่วมหรือขยายโปรเจกต์ MANTA คู่มือนี้ครอบคลุมเรื่องสถาปัตยกรรม การจัดระเบียบโค้ด ขั้นตอนการพัฒนา และแนวทางการส่งการปรับปรุงต่างๆ

## การตั้งค่าสภาพแวดล้อมการพัฒนา

### ความต้องการเบื้องต้น

- Python 3.9 หรือสูงกว่า
- Git
- Visual Studio Code, PyCharm หรือ IDE ที่คุณชอบ
- Docker (ทางเลือก สำหรับการพัฒนาแบบคอนเทนเนอร์)
- Raspberry Pi 5 Model B สำหรับการทดสอบการทำงานจริง

### การตั้งค่าสภาพแวดล้อมการพัฒนา

1. **โคลนรีโพสิทอรี**:

   ```bash
   git clone https://github.com/yourusername/manta.git
   cd manta
   ```

2. **สร้างสภาพแวดล้อมเสมือน**:

   ```bash
   python -m venv venv
   source venv/bin/activate  # บน Windows: venv\Scripts\activate
   ```

3. **ติดตั้งแพ็คเกจสำหรับการพัฒนา**:

   ```bash
   pip install -r requirements-dev.txt
   ```

4. **ติดตั้ง pre-commit hooks**:

   ```bash
   pre-commit install
   ```

5. **รันทดสอบเพื่อตรวจสอบการตั้งค่า**:
   ```bash
   pytest tests/
   ```

## โครงสร้างโปรเจกต์

โปรเจกต์ MANTA ใช้โครงสร้างแบบโมดูลาร์:

```
manta/
├── camera/              # โมดูลหลักสำหรับกล้องและการตรวจจับ
│   ├── main.py          # จุดเริ่มต้นของแอปพลิเคชัน
│   ├── detection.py     # โมดูลตรวจจับบุคคล
│   ├── reid.py          # โมดูลจดจำบุคคล
│   ├── logger.py        # ฟังก์ชันการบันทึกข้อมูล
│   └── uploader.py      # การเชื่อมต่อกับ Firebase
├── config/              # ไฟล์การกำหนดค่า
│   ├── config.yaml      # การกำหนดค่าหลัก
│   └── config.sample.yaml  # ตัวอย่างการกำหนดค่า
├── models/              # ไดเร็กทอรีสำหรับโมเดล ML
│   ├── yolov8n.onnx     # โมเดลตรวจจับ YOLO
│   └── requirements.txt # แพ็คเกจที่จำเป็นสำหรับโมเดล
├── dataset/             # ข้อมูลสำหรับการฝึกสอนและทดสอบ
│   ├── images/          # ภาพตัวอย่างสำหรับการทดสอบ
│   └── labels/          # คำอธิบายประกอบภาพ
├── firebase/            # การเชื่อมต่อ Firebase
│   ├── firebase_config.json  # ข้อมูลประจำตัว Firebase
│   └── firebase_utils.py     # ฟังก์ชันอรรถประโยชน์สำหรับ Firebase
├── n8n/                 # การทำงานอัตโนมัติด้วย n8n
│   ├── docker-compose.yml    # การตั้งค่า n8n
│   └── workflows/            # ตัวอย่างเวิร์กโฟลว์
├── utils/               # ฟังก์ชันอรรถประโยชน์
│   ├── camera_utils.py  # อรรถประโยชน์ที่เกี่ยวข้องกับกล้อง
│   └── vector_utils.py  # การดำเนินการกับเวกเตอร์สำหรับ ReID
├── logs/                # ไฟล์บันทึก
├── tests/               # การทดสอบแบบยูนิตและการบูรณาการ
│   ├── test_detection.py
│   ├── test_reid.py
│   └── ...
├── docs/                # เอกสาร
├── scripts/             # สคริปต์อรรถประโยชน์
├── .github/             # เวิร์กโฟลว์ GitHub
├── requirements.txt     # แพ็คเกจสำหรับการใช้งานจริง
├── requirements-dev.txt # แพ็คเกจสำหรับการพัฒนา
├── setup.py             # การตั้งค่าแพ็คเกจ
└── README.md            # ภาพรวมโปรเจกต์
```

## ส่วนประกอบหลัก

### 1. โมดูลกล้อง (`camera/main.py`)

นี่คือจุดเริ่มต้นของระบบ MANTA โมดูลนี้ทำหน้าที่ประสานงานกับส่วนประกอบอื่นๆ ทั้งหมดและมีการทำงานหลักในรูปแบบลูป

หน้าที่หลัก:

- เริ่มต้นส่วนประกอบทั้งหมดตามการกำหนดค่า
- ประมวลผลเฟรมวิดีโอจากกล้อง
- ประสานงานการตรวจจับ การจดจำบุคคล และการบันทึกข้อมูล
- จัดการกับอินพุตของผู้ใช้เมื่ออยู่ในโหมดดีบัก

### 2. โมดูลตรวจจับ (`camera/detection.py`)

จัดการกับการตรวจจับบุคคลโดยใช้โมเดล YOLO

ส่วนประกอบหลัก:

- คลาส `PersonDetector`: ห่อหุ้มโมเดล YOLO
- การโหลดโมเดลและการประมวลผลข้อมูลเข้า/ออก
- การแยกและกรองกรอบขอบเขต (bounding box)

จุดขยายเพิ่มเติม:

- รองรับโมเดลที่แตกต่างกัน (YOLOv5, YOLOv8 ฯลฯ)
- ตรรกะการประมวลผลหลังเสร็จสิ้นที่กำหนดเอง
- การเร่งความเร็วด้วยฮาร์ดแวร์ (CUDA, TensorRT ฯลฯ)

### 3. โมดูลจดจำบุคคล (Re-Identification) (`camera/reid.py`)

จัดการการติดตามบุคคลระหว่างเฟรมโดยใช้เวกเตอร์คุณลักษณะ

ส่วนประกอบหลัก:

- คลาส `PersonReIdentifier`: จัดการการแยกคุณลักษณะและการเปรียบเทียบ
- การจัดเก็บเวกเตอร์และการคำนวณความเหมือน
- การจัดการเวลาของรหัสประจำตัวที่รู้จัก

จุดขยายเพิ่มเติม:

- โมเดลการแยกคุณลักษณะที่กำหนดเอง
- เมตริกความเหมือนทางเลือก
- อัลกอริทึมการติดตามขั้นสูง

### 4. โมดูลบันทึกข้อมูล (`camera/logger.py`)

จัดการการบันทึกกิจกรรมและการเก็บรักษาข้อมูล

ส่วนประกอบหลัก:

- คลาส `ActivityLogger`: บันทึกเหตุการณ์การตรวจจับ
- การจัดเก็บบันทึกข้อมูลในรูปแบบ JSON
- การหมุนเวียนและการล้างบันทึกข้อมูล

จุดขยายเพิ่มเติม:

- รูปแบบบันทึกข้อมูลเพิ่มเติม
- การวิเคราะห์ที่กำหนดเอง
- แบ็กเอนด์การจัดเก็บทางเลือก

### 5. โมดูลอัปโหลด (`camera/uploader.py`)

จัดการการซิงโครไนซ์กับคลาวด์ Firebase

ส่วนประกอบหลัก:

- คลาส `FirebaseUploader`: จัดการการสื่อสารกับ Firebase
- การแคชออฟไลน์และตรรกะการลองใหม่
- การอัปโหลดเป็นชุด

จุดขยายเพิ่มเติม:

- รองรับบริการคลาวด์ทางเลือก
- การแปลงข้อมูลที่กำหนดเอง
- กลยุทธ์การซิงโครไนซ์ขั้นสูง

## ขั้นตอนการพัฒนา

### ขั้นตอนการพัฒนาฟีเจอร์

1. **การสร้างปัญหา (Issue)**:

   - สร้าง GitHub issue ที่อธิบายฟีเจอร์หรือบัก
   - ใช้ป้ายกำกับ (label) ที่เหมาะสม (enhancement, bug ฯลฯ)

2. **การสร้างสาขา (Branch)**:

   - สร้างสาขาฟีเจอร์จาก `main`
   - ใช้ชื่อที่มีความหมาย: `feature/add-trt-support` หรือ `fix/camera-reconnect`

3. **การพัฒนา**:

   - พัฒนาฟีเจอร์หรือแก้ไขบัก
   - เพิ่มการทดสอบที่เหมาะสม
   - อัปเดตเอกสาร

4. **การทดสอบ**:

   - รันการทดสอบหน่วย: `pytest tests/unit/`
   - รันการทดสอบบูรณาการ: `pytest tests/integration/`
   - ทำการทดสอบด้วยตนเองตามความจำเป็น

5. **คำขอดึง (Pull Request)**:

   - สร้างคำขอดึงไปยังสาขา `main`
   - อ้างอิงปัญหาที่เกี่ยวข้อง
   - กรอกแบบฟอร์ม PR

6. **การตรวจสอบโค้ด**:

   - แก้ไขตามความคิดเห็นของผู้ตรวจสอบ
   - ตรวจสอบให้แน่ใจว่าผ่านการตรวจสอบทั้งหมด

7. **การรวม**:
   - PR ถูกรวมหลังจากได้รับการอนุมัติ
   - ลบสาขาฟีเจอร์

### มาตรฐานการเขียนโค้ด

MANTA ใช้มาตรฐานการเขียนโค้ดดังนี้:

1. **รูปแบบ Python**:

   - ปฏิบัติตาม PEP 8 สำหรับรูปแบบโค้ด
   - ใช้คำแนะนำประเภท (type hints) เมื่อใดก็ตามที่เป็นไปได้
   - ความยาวบรรทัดสูงสุด: 100 ตัวอักษร

2. **เอกสาร**:

   - จัดทำเอกสารสำหรับฟังก์ชัน คลาส และเมธอดสาธารณะทั้งหมด
   - ใช้ docstrings ตามคู่มือสไตล์ของ Google
   - รักษาเอกสารให้ทันสมัยกับการเปลี่ยนแปลงโค้ด

3. **การทดสอบ**:

   - เขียนการทดสอบหน่วยสำหรับฟังก์ชันการทำงานใหม่ทั้งหมด
   - ตั้งเป้าหมายอย่างน้อย 80% ของความครอบคลุมโค้ด
   - รวมการทดสอบบูรณาการสำหรับการปฏิสัมพันธ์ระหว่างส่วนประกอบ

4. **ข้อความคอมมิต**:
   - ใช้ข้อความคอมมิตที่มีความหมาย
   - ปฏิบัติตามรูปแบบคอมมิตแบบแผน: `type(scope): description`
   - ตัวอย่าง: `feat(detection): add TensorRT support`, `fix(camera): handle reconnection`

## การขยาย MANTA

### การเพิ่มโมเดลตรวจจับใหม่

การนำโมเดลตรวจจับวัตถุที่แตกต่างมาใช้:

1. **สร้าง Model Wrapper**:
   - สร้างคลาสใหม่ใน `camera/detection.py` หรือในไฟล์ใหม่
   - ใช้อินเทอร์เฟซเดียวกับ `PersonDetector`

```python
class CustomModelDetector:
    def __init__(self, model_path, confidence_threshold=0.5, **kwargs):
        # เริ่มต้นโมเดลของคุณ
        pass

    def detect(self, frame):
        # ใส่ตรรกะการตรวจจับ
        # ส่งคืนในรูปแบบ: [[x1, y1, x2, y2, confidence, class_id], ...]
        pass
```

2. **อัปเดตการกำหนดค่า**:

   - เพิ่มพารามิเตอร์เฉพาะของโมเดลใน `config.yaml`
   - เพิ่มพารามิเตอร์ตัวเลือกโมเดล

3. **แก้ไขลูปหลัก**:
   - อัปเดต `main.py` เพื่อใช้ตัวตรวจจับของคุณตามการกำหนดค่า

### การใช้วิธีจดจำบุคคลที่กำหนดเอง

การใช้วิธีการจดจำบุคคลที่แตกต่าง:

1. **สร้างคลาส ReID**:
   - สร้างคลาสใหม่ใน `camera/reid.py` หรือในไฟล์ใหม่
   - ใช้อินเทอร์เฟซเดียวกับ `PersonReIdentifier`

```python
class CustomReIdentifier:
    def __init__(self, **kwargs):
        # เริ่มต้นตรรกะการจดจำบุคคลของคุณ
        pass

    def process(self, person_img):
        # ประมวลผลภาพบุคคล
        # ส่งคืน: (is_new_person, person_hash)
        pass
```

2. **อัปเดตการกำหนดค่า**:

   - เพิ่มพารามิเตอร์ที่เหมาะสมใน `config.yaml`

3. **รวมในลูปหลัก**:
   - อัปเดต `main.py` เพื่อใช้ตัวจดจำบุคคลของคุณ

### การเพิ่มการรองรับผู้ให้บริการคลาวด์

การเพิ่มการรองรับผู้ให้บริการคลาวด์อื่นนอกเหนือจาก Firebase:

1. **สร้าง Cloud Uploader**:
   - สร้างไฟล์ใหม่เช่น `camera/cloud_providers/aws_uploader.py`
   - ใช้อินเทอร์เฟซเดียวกับ `FirebaseUploader`

```python
class AWSUploader:
    def __init__(self, config_path, **kwargs):
        # เริ่มต้นไคลเอนต์ AWS
        pass

    def upload_log(self, log_entry):
        # อัปโหลดไป AWS
        pass

    def flush(self):
        # อัปโหลดรายการที่รอดำเนินการ
        pass
```

2. **อัปเดตการกำหนดค่า**:

   - เพิ่มตัวเลือกผู้ให้บริการคลาวด์ใน `config.yaml`
   - เพิ่มการกำหนดค่าเฉพาะของผู้ให้บริการ

3. **รูปแบบ Factory**:
   - ใช้รูปแบบ factory ใน `main.py` เพื่อสร้าง uploader ที่เหมาะสม

### การสร้างโมดูลวิเคราะห์ที่กำหนดเอง

การเพิ่มการวิเคราะห์เฉพาะทาง:

1. **สร้างคลาสวิเคราะห์**:
   - สร้างไฟล์ใหม่เช่น `utils/analytics.py`
   - ใส่ตรรกะการวิเคราะห์ของคุณ

```python
class OccupancyAnalytics:
    def __init__(self, **kwargs):
        # เริ่มต้นการวิเคราะห์
        self.data = []

    def process_log(self, log_entry):
        # ประมวลผลรายการบันทึก
        self.data.append(log_entry)

    def generate_report(self):
        # สร้างรายงานการวิเคราะห์
        return {
            "peak_time": self._calculate_peak_time(),
            "average_occupancy": self._calculate_average_occupancy(),
            # เมตริกอื่นๆ
        }
```

2. **การบูรณาการ**:
   - เพิ่มในลูปหลักหรือสร้างสคริปต์ประมวลผลแยกต่างหาก
   - กำหนดค่าวิธีสร้างและจัดเก็บการวิเคราะห์

## การทดสอบ

### การทดสอบหน่วย (Unit Testing)

การทดสอบหน่วยตรวจสอบส่วนประกอบแต่ละส่วนแยกต่างหาก:

```python
# tests/unit/test_detection.py
import pytest
from camera.detection import PersonDetector
import numpy as np
import cv2

def test_person_detector_initialization():
    detector = PersonDetector(model_path="models/yolov8n.onnx")
    assert detector is not None

def test_person_detection():
    detector = PersonDetector(model_path="models/yolov8n.onnx")
    # สร้างภาพทดสอบที่มีบุคคล
    img = np.zeros((640, 640, 3), dtype=np.uint8)
    # เพิ่มบุคคลสังเคราะห์ลงในภาพ
    cv2.rectangle(img, (100, 100), (300, 500), (255, 255, 255), -1)

    detections = detector.detect(img)

    # ตรวจสอบการตรวจจับ
    assert len(detections) >= 1
```

รันการทดสอบหน่วยด้วย:

```bash
pytest tests/unit/
```

### การทดสอบบูรณาการ (Integration Testing)

การทดสอบบูรณาการตรวจสอบการทำงานร่วมกันระหว่างส่วนประกอบ:

```python
# tests/integration/test_detection_reid.py
import pytest
from camera.detection import PersonDetector
from camera.reid import PersonReIdentifier
import cv2

def test_detection_reid_pipeline():
    detector = PersonDetector(model_path="models/yolov8n.onnx")
    reid = PersonReIdentifier()

    # โหลดภาพทดสอบ
    img = cv2.imread("tests/data/person.jpg")

    # ตรวจจับบุคคล
    detections = detector.detect(img)
    assert len(detections) >= 1

    # แยกภาพบุคคล
    x1, y1, x2, y2 = map(int, detections[0][:4])
    person_img = img[y1:y2, x1:x2]

    # ประมวลผลผ่าน ReID
    is_new, person_hash = reid.process(person_img)

    # การตรวจจับครั้งแรกควรเป็นบุคคลใหม่
    assert is_new == True
    assert person_hash is not None

    # ประมวลผลภาพเดิมอีกครั้ง ไม่ควรเป็นบุคคลใหม่
    is_new, person_hash2 = reid.process(person_img)
    assert is_new == False
```

รันการทดสอบบูรณาการด้วย:

```bash
pytest tests/integration/
```

### การทดสอบประสิทธิภาพ (Performance Testing)

การทดสอบประสิทธิภาพวัดความสามารถของระบบ:

```python
# tests/performance/test_detection_speed.py
import pytest
import time
import cv2
import numpy as np
from camera.detection import PersonDetector

def test_detection_performance():
    detector = PersonDetector(model_path="models/yolov8n.onnx")
    img = cv2.imread("tests/data/crowd.jpg")

    # การรันอุ่นเครื่อง
    detector.detect(img)

    # การวัดประสิทธิภาพ
    iterations = 50
    start = time.time()
    for _ in range(iterations):
        detector.detect(img)
    end = time.time()

    avg_time = (end - start) / iterations
    fps = 1 / avg_time

    print(f"เวลาเฉลี่ยในการตรวจจับ: {avg_time:.4f}s ({fps:.2f} FPS)")

    # ตรวจสอบประสิทธิภาพที่เหมาะสม
    assert fps > 5  # FPS ขั้นต่ำที่ยอมรับได้
```

รันการทดสอบประสิทธิภาพด้วย:

```bash
pytest tests/performance/
```

## การปรับใช้งาน (Deployment)

### การปรับใช้งานด้วย Docker

สร้างและปรับใช้โดยใช้ Docker:

```bash
# สร้างอิมเมจ
docker build -t manta:latest .

# รันคอนเทนเนอร์
docker run -d --name manta-cam1 \
  --device=/dev/video0:/dev/video0 \
  -v $(pwd)/config:/app/config \
  -v $(pwd)/logs:/app/logs \
  manta:latest
```

### การปรับใช้งานบน Raspberry Pi

การปรับใช้งานที่เหมาะสมสำหรับ Raspberry Pi:

1. **ติดตั้งแพ็คเกจที่จำเป็น**:

   ```bash
   pip install -r requirements-rpi.txt
   ```

2. **ใช้การกำหนดค่าที่เหมาะสม**:

   ```bash
   cp config/config.rpi.yaml config/config.yaml
   ```

3. **รันเป็นบริการ**:
   ```bash
   # สร้างบริการ systemd
   sudo cp scripts/manta.service /etc/systemd/system/
   sudo systemctl enable manta
   sudo systemctl start manta
   ```

### การปรับใช้งานบน Cloud VM

สำหรับการปรับใช้งานบน VM บนคลาวด์:

1. **ตั้งค่าโหมดไร้หน้าจอ**:

   - ใช้แหล่งที่มาของกล้องเสมือนหรือไฟล์วิดีโอ
   - ปิดการแสดงผลดีบัก

2. **กำหนดค่าเครือข่าย**:

   - ตั้งค่ากฎไฟร์วอลล์ที่เหมาะสม
   - กำหนดค่า IP แบบคงที่หากจำเป็น

3. **ตั้งค่าการตรวจสอบ**:
   - ใช้เครื่องมือตรวจสอบของผู้ให้บริการคลาวด์
   - กำหนดค่าการแจ้งเตือนสำหรับปัญหาระบบ

## แนวทางการมีส่วนร่วม

### กระบวนการ Pull Request

1. **สร้าง Feature/Bug Branch**:

   ```bash
   git checkout -b feature/your-feature-name
   ```

2. **ทำการเปลี่ยนแปลงและคอมมิต**:

   ```bash
   git add .
   git commit -m "feat(component): description of changes"
   ```

3. **รันการทดสอบและการตรวจสอบโค้ด**:

   ```bash
   pytest
   flake8 manta
   ```

4. **พุชไปยังฟอร์กของคุณ**:

   ```bash
   git push origin feature/your-feature-name
   ```

5. **สร้าง Pull Request**:
   - ไปที่ GitHub และสร้าง PR ไปยังรีโพสิทอรีหลัก
   - กรอกแบบฟอร์ม PR
   - อ้างอิงปัญหาที่เกี่ยวข้อง

### รายการตรวจสอบการรีวิวโค้ด

- โค้ดปฏิบัติตามมาตรฐานการเขียนโค้ดของโปรเจกต์หรือไม่?
- มีการทดสอบที่เหมาะสมสำหรับการเปลี่ยนแปลงหรือไม่?
- เอกสารได้รับการอัปเดตเพื่อสะท้อนการเปลี่ยนแปลงหรือไม่?
- การตรวจสอบ CI ทั้งหมดผ่านหรือไม่?
- โค้ดตอบสนองความต้องการของปัญหาหรือไม่?
- มีข้อกังวลเกี่ยวกับความปลอดภัย ประสิทธิภาพ หรือความสามารถในการขยายตัวหรือไม่?

## คำถามที่พบบ่อยสำหรับนักพัฒนา

### ถาม: ฉันจะเพิ่มการรองรับกล้องประเภทใหม่ได้อย่างไร?

ตอบ: ขยายไฟล์ `camera_utils.py` เพื่อจัดการกับกล้องประเภทใหม่:

1. เพิ่มฟังก์ชันใหม่เพื่อเริ่มต้นกล้อง
2. อัปเดตฟังก์ชัน `setup_camera` เพื่อใช้การเริ่มต้นใหม่ของคุณ
3. เพิ่มพารามิเตอร์การกำหนดค่าที่เหมาะสม

### ถาม: ฉันจะปรับแต่ง MANTA สำหรับแพลตฟอร์มฮาร์ดแวร์เฉพาะได้อย่างไร?

ตอบ: พิจารณาขั้นตอนเหล่านี้:

1. เลือกขนาดโมเดลที่เหมาะสมกับฮาร์ดแวร์ของคุณ
2. เปิดใช้งานการเร่งความเร็วด้วยฮาร์ดแวร์หากมี
3. ปรับความละเอียดและอัตราเฟรมในการกำหนดค่า
4. โปรไฟล์แอปพลิเคชันเพื่อระบุคอขวด
5. ใช้การปรับแต่งเฉพาะแพลตฟอร์ม

### ถาม: วิธีที่ดีที่สุดในการดีบักไปป์ไลน์การตรวจจับคืออะไร?

ตอบ: ใช้แนวทางเหล่านี้:

1. เปิดใช้งานแฟล็ก `--debug` เพื่อดูการแสดงผลภาพ
2. ตั้งค่าระดับการบันทึกเป็น DEBUG ในการกำหนดค่า
3. เพิ่มจุดหยุดใน IDE ของคุณสำหรับการดีบักทีละขั้นตอน
4. ใช้การแสดงผลของ OpenCV เพื่อตรวจสอบผลลัพธ์ระหว่างกลาง

### ถาม: ฉันจะใช้ระบบการแจ้งเตือนที่กำหนดเองได้อย่างไร?

ตอบ: สร้างโมดูลการแจ้งเตือน:

1. สร้างไฟล์ใหม่เช่น `utils/notifications.py`
2. ใส่ตรรกะการแจ้งเตือนของคุณ (อีเมล, SMS ฯลฯ)
3. เชื่อมต่อกับเหตุการณ์การตรวจจับใน `main.py`
4. เพิ่มพารามิเตอร์การกำหนดค่าสำหรับระบบการแจ้งเตือนของคุณ

## หัวข้อขั้นสูง

### การปรับแต่งโมเดล

ปรับแต่งโมเดลเพื่อประสิทธิภาพที่ดีขึ้น:

1. **การลดความแม่นยำ (Quantization)**:

   - แปลงโมเดลเป็นความแม่นยำ INT8
   - ใช้เครื่องมือเช่น API การลดความแม่นยำของ ONNX Runtime

2. **การตัดแต่ง (Pruning)**:

   - ลบน้ำหนักโมเดลที่ไม่จำเป็น
   - ใช้เทคนิคเช่นการตัดแต่งตามขนาด

3. **การกลั่นความรู้ (Knowledge Distillation)**:
   - ฝึกสอนโมเดลที่เล็กกว่าให้เลียนแบบโมเดลขนาดใหญ่
   - บีบอัดความรู้ของโมเดลในขณะที่รักษาความแม่นยำ

### การฝึกสอนโมเดลเอง

ฝึกสอนโมเดลที่กำหนดเองสำหรับสภาพแวดล้อมเฉพาะ:

1. **การเก็บข้อมูล**:

   - เก็บข้อมูลเฉพาะโดเมน
   - ใช้โครงสร้างไดเร็กทอรี `dataset`

2. **การฝึกสอน**:

   - ใช้ API การฝึกสอนของ YOLOv8
   - ปรับแต่งโมเดลที่ผ่านการฝึกสอนมาแล้ว

3. **การส่งออก**:
   - แปลงโมเดลที่ฝึกสอนแล้วเป็นรูปแบบ ONNX
   - ปรับแต่งสำหรับการอนุมาน

### การวิเคราะห์แบบเรียลไทม์

ใช้การวิเคราะห์ขั้นสูง:

1. **การติดตามจำนวนผู้คน**:

   - ตรวจสอบความจุของห้องแบบเรียลไทม์
   - สร้างการแจ้งเตือนสำหรับขีดจำกัดความจุ

2. **การวิเคราะห์การไหลของการจราจร**:

   - ติดตามรูปแบบการเคลื่อนไหว
   - ระบุคอขวด

3. **การทำแผนที่ความร้อน (Heat Mapping)**:
   - แสดงความหนาแน่นของกิจกรรม
   - วิเคราะห์การใช้พื้นที่

## แผนภาพสถาปัตยกรรมระบบ

MANTA มีแผนภาพที่สร้างขึ้นด้วย D2 (https://d2lang.com/) เพื่อช่วยให้เข้าใจสถาปัตยกรรมของระบบได้ดีขึ้น:

### แผนภาพที่มีอยู่

1. **system-architecture.d2**: แสดงสถาปัตยกรรมระบบ MANTA ทั้งหมด รวมถึงองค์ประกอบของฮาร์ดแวร์ ระบบหลัก และบริการภายนอก
2. **data-flow.d2**: แสดงการไหลของข้อมูลผ่านระบบ ตั้งแต่การรับภาพจากกล้องไปจนถึงการวิเคราะห์และการจัดเก็บ
3. **network-config.d2**: แสดงการกำหนดค่าเครือข่ายทั้งหมด รวมถึงการเชื่อมต่อ WiFi Direct และ WebCam Protocol
4. **camera-config.d2**: แสดงการกำหนดค่ากล้องและการทำงานของระบบการกำหนดค่าระยะไกล
5. **component-diagram.d2**: แสดงความสัมพันธ์ระหว่างคอมโพเนนต์ในโค้ด เช่น คลาส โมดูล และไฟล์การกำหนดค่า

### การใช้งานแผนภาพ

1. **สำหรับการพัฒนา**: ใช้แผนภาพเหล่านี้เพื่อทำความเข้าใจโครงสร้างและความสัมพันธ์ระหว่างส่วนประกอบต่างๆ
2. **สำหรับการขยาย**: เมื่อคุณเพิ่มฟีเจอร์ใหม่ ให้อัปเดตแผนภาพที่เกี่ยวข้องเพื่อสะท้อนการเปลี่ยนแปลง
3. **สำหรับเอกสาร**: ใช้แผนภาพเพื่อประกอบการอธิบายในเอกสารเทคนิค

### การอัปเดตแผนภาพ

1. ติดตั้ง D2 ตามคำแนะนำใน [docs/d2/README.md](../d2/README.md)
2. แก้ไขไฟล์ .d2 ที่ต้องการด้วยตัวแก้ไขข้อความ
3. สร้างแผนภาพใหม่โดยใช้คำสั่ง:
   ```bash
   d2 docs/d2/your-diagram.d2 docs/d2/your-diagram.svg
   ```
4. คอมมิตการเปลี่ยนแปลงทั้งไฟล์ .d2 และไฟล์ .svg ที่สร้างขึ้น

คุณสามารถใช้เครื่องมือออนไลน์ที่ [play.d2lang.com](https://play.d2lang.com/) เพื่อทดสอบและแก้ไขแผนภาพเหล่านี้

## แหล่งข้อมูล

- [เอกสาร YOLOv8](https://docs.ultralytics.com/)
- [เอกสาร ONNX Runtime](https://onnxruntime.ai/)
- [เอกสาร OpenCV](https://docs.opencv.org/)
- [เอกสาร Firebase](https://firebase.google.com/docs)
- [เอกสาร n8n](https://docs.n8n.io/)
- [เอกสาร D2](https://d2lang.com/tour/intro)

## ใบอนุญาต

MANTA ได้รับอนุญาตภายใต้ MIT License - ดูไฟล์ LICENSE สำหรับรายละเอียด
